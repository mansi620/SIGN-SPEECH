{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOqWkC/7ocfUw4psTIVuduc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mansi620/SIGN-SPEECH/blob/main/Copy_of_HANDSWESPEAK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRgxEjVjV9F5",
        "outputId": "7beb2b04-348c-4ec8-cff8-0fb4d4ada751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!(pip install streamlit -q)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yacs\n",
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9CREDyJW0w5",
        "outputId": "0e4db948-35da-4ba9-c9ce-28cd17d36a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs) (6.0)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==3.*\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.12.7)\n",
            "Collecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17414 sha256=66a9aaf2b17bca6510294fd0026bc693a384b6bcad5b1ab897939719aeb7f84c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/25/af/715361fa79594524c89c75d293def652045f3fdce6ca398712\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, sniffio, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukataNTTW1BI",
        "outputId": "3f37a216-d130-41c3-9cda-3c1dbc6cfee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/exec.sh\n",
        "#!/bin/sh\n",
        "python /content/drive/MyDrive/SAMSLR/data-prepare/wholepose/demo.py\n",
        "python /content/drive/MyDrive/SAMSLR/SL-GCN/data_gen/sign_gendata.py\n",
        "python /content/drive/MyDrive/SAMSLR/SL-GCN/data_gen/gen_bone_data.py\n",
        "python /content/drive/MyDrive/SAMSLR/SL-GCN/data_gen/gen_motion_data.py\n",
        "python /content/drive/MyDrive/SAMSLR/SL-GCN/main.py --config /content/drive/MyDrive/SAMSLR/SL-GCN/config/sign/test/test_joint.yaml\n",
        "python /content/drive/MyDrive/SAMSLR/SL-GCN/main.py --config /content/drive/MyDrive/SAMSLR/SL-GCN/config/sign/test/test_bone.yaml\n",
        "python /content/drive/MyDrive/SAMSLR/SL-GCN/main.py --config /content/drive/MyDrive/SAMSLR/SL-GCN/config/sign/test/test_joint_motion.yaml\n",
        "python /content/drive/MyDrive/SAMSLR/SL-GCN/main.py --config /content/drive/MyDrive/SAMSLR/SL-GCN/config/sign/test/test_bone_motion.yaml\n",
        "python /content/drive/MyDrive/SAMSLR/ensemble/gcn/ensemble_wo_val.py\n",
        "python /content/drive/MyDrive/SAMSLR/SSTCN/data_process/wholepose_features_extraction.py\n",
        "python /content/drive/MyDrive/SAMSLR/SSTCN/test.py\n",
        "python /content/drive/MyDrive/SAMSLR/ensemble/ensemble_multimodal_rgb.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov7nmNAaW7Ga",
        "outputId": "ab81d89b-234c-4f52-afb6-ceca095942fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/exec.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "result = subprocess.run([\"chmod\",\"u+x\",\"exec.sh\"], stdout=subprocess.PIPE, text=True)\n",
        "print(result.stdout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNNylKQMXA2E",
        "outputId": "e55dc6f1-79fd-4c03-a387-a4e2540e4b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/SAMSLR/app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import streamlit.components.v1 as components\n",
        "from googletrans import Translator\n",
        "translator=Translator()\n",
        "\n",
        "components.html(\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "        \n",
        "            \n",
        "                Sign Language Recognition\n",
        "            \n",
        "        \n",
        "    \n",
        "    \"\"\",\n",
        "    height=200\n",
        ")\n",
        "\n",
        "st.write(\"Please Upload Video\")\n",
        "vid_file = st.file_uploader(\"Upload video\", type=[\"mp4\"])\n",
        "# video_file = open('/content/drive/MyDrive/data/result_compressed.mp4', 'rb')\n",
        "if vid_file!=None:\n",
        "  with open(os.path.join(\"/content/drive/MyDrive/SAMSLR/input-video\",vid_file.name),\"wb\") as f:\n",
        "         f.write(vid_file.getbuffer())\n",
        "  save_path = \"/content/drive/MyDrive/SAMSLR/input-video/\"+vid_file.name\n",
        "  st.write(save_path)\n",
        "  compressed_path = \"/content/drive/MyDrive/SAMSLR/input-video/result_compressed.mp4\"\n",
        "  os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
        "  video_file = open('/content/drive/MyDrive/SAMSLR/input-video/result_compressed.mp4', 'rb')\n",
        "  video_bytes = video_file.read()\n",
        "  st.video(video_bytes)\n",
        "  os.system(\"rm /content/drive/MyDrive/SAMSLR/input-video/result_compressed.mp4\")\n",
        "  input_path = '/content/drive/MyDrive/input'\n",
        "  result_path = '/content/drive/MyDrive/results'\n",
        "  test_features_path = '/content/drive/MyDrive/results/test_features'\n",
        "\n",
        "  # Get path of video to be classified\n",
        "  video_path = save_path\n",
        "  video_label_path = '/content/drive/MyDrive/data/val30_labels.csv'\n",
        "  # Create input and results directories\n",
        "  if not os.path.exists(input_path):\n",
        "      os.makedirs(input_path)\n",
        "  if not os.path.exists(result_path):\n",
        "      os.makedirs(result_path)\n",
        "  work_dir_path = '/content/drive/MyDrive/results/work_dir'\n",
        "  if not os.path.exists(work_dir_path):\n",
        "      os.makedirs(work_dir_path)\n",
        "  if not os.path.exists(test_features_path):\n",
        "      os.makedirs(test_features_path)\n",
        "  # Copy to input folder\n",
        "  shutil.copy(video_path,input_path+'/test_example_color.mp4')\n",
        "\n",
        "  # Create csv for input file\n",
        "  df=pd.read_csv(video_label_path)\n",
        "  video_name = video_path.split('/')[-1][:-10]\n",
        "  new_df = df.loc[(df['file_name']==video_name)]\n",
        "  new_df.drop(['Unnamed: 0'], axis=1,inplace = True)\n",
        "  print(new_df)\n",
        "  new_df = new_df.values.tolist()\n",
        "  new_df[0][0] = 'test_example'\n",
        "  new_df = pd.DataFrame(new_df)\n",
        "  new_df.columns = ['file_name','class_id']\n",
        "  new_df.to_csv('/content/drive/MyDrive/results/test_labels.csv')\n",
        "\n",
        "\n",
        "  # Create npy directory\n",
        "  npy_path = result_path+'/npy3'\n",
        "  if not os.path.exists(npy_path):\n",
        "      os.makedirs(npy_path)\n",
        "\n",
        "  st.write(\"Your video is being processed\")\n",
        "  \n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Generating skeleton npy features for input video')\n",
        "\n",
        "  # From npy files, create joint data npy file\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Generating Joint features')\n",
        "\n",
        "  # From npy file, create bone data npy file\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Generating Bone features')\n",
        "\n",
        "  # From npy file, create motion data npy files for join and bone\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Generating Joint & Bone motion features')\n",
        "\n",
        "  # Create joint pkl file for ensemble\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Creating joint pkl file for ensemble')\n",
        "\n",
        "  # Create bone pkl file for ensemble\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Creating bone pkl file for ensemble')\n",
        "\n",
        "  # Create joint motion pkl file for ensemble\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Creating joint motion pkl file for ensemble')\n",
        "\n",
        "  # Create bone motion pkl file for ensemble\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Creating bone motion pkl file for ensemble')\n",
        "\n",
        "  # Create SLGCN ensemble\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Generating score from SLGCN skeleton features')\n",
        "\n",
        "# Create SSTCN features\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Generating SSTCN features')\n",
        "\n",
        "  # Generate Score from SSTCN\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Generating score from SSTCN features')\n",
        "\n",
        "  # Making Final Predictions\n",
        "  st.write('-----------------------------------------------------')\n",
        "  st.write('Making final predictions')\n",
        "\n",
        "  result = subprocess.run(\"./exec.sh\", stderr=subprocess.PIPE, text=True)\n",
        "  print(result.stderr)\n",
        "\n",
        "\n",
        "  # Print english output\n",
        "  output = pd.read_csv('/content/drive/MyDrive/results/predictions_rgb.csv')\n",
        "  if len(output)!=0:\n",
        "    output = output.values.tolist()\n",
        "    class_id = output[-1][-1]\n",
        "\n",
        "    print('Class ID is : ',class_id)\n",
        "\n",
        "    mapping = pd.read_csv('/content/drive/MyDrive/Class-ID Mapping.csv')\n",
        "    mapping = mapping[mapping['ClassId']==class_id]\n",
        "    mapping_output = mapping.values.tolist()\n",
        "    english_word = mapping_output[-1][-1]\n",
        "    sentence = ' '.join(english_word.split('_'))\n",
        "    print('English word is :', sentence)\n",
        "    output=pd.DataFrame(columns=['Unnamed: 0', 'file_name', 'class_id'])\n",
        "    output.to_csv(\"/content/drive/MyDrive/results/predictions_rgb.csv\",index=False)\n",
        "    output='English word is : '+sentence\n",
        "    st.title(output)\n",
        "    result_kannada = translator.translate(sentence, dest='kn')\n",
        "    result_hindi=translator.translate(sentence, dest='hi')\n",
        "    kannada_output=\"Translated to Kannada: \"+result_kannada.text\n",
        "    hindi_output=\"Translated to Hindi: \"+result_hindi.text\n",
        "    st.title(kannada_output)\n",
        "    st.title(hindi_output)\n",
        "    \n",
        "    \n",
        "  # os.system(\"rm \"+save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "L3L_K6WvXHcO",
        "outputId": "c253009d-d3d1-4e64-eb1b-8c96493f2b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/SAMSLR/app.py\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1dc5bdf5eca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/SAMSLR/app.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'import streamlit as st\\nimport os\\nfrom IPython.display import HTML\\nfrom base64 import b64encode\\nimport shutil\\nimport pandas as pd\\nimport subprocess\\nimport streamlit.components.v1 as components\\nfrom googletrans import Translator\\ntranslator=Translator()\\n\\ncomponents.html(\\n    \"\"\"\\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n        \\n            \\n                Sign Language Recognition\\n            \\n        \\n    \\n    \"\"\",\\n    height=200\\n)\\n\\nst.write(\"Please Upload Video\")\\nvid_file = st.file_uploader(\"Upload video\", type=[\"mp4\"])\\n# video_file = open(\\'/content/drive/MyDrive/data/result_compressed.mp4\\', \\'rb\\')\\nif vid_file!=None:\\n  with open(os.path.join(\"/content/drive/MyDrive/SAMSLR/input-video\",vid_file.name),\"wb\") as f:\\n         f.write(vid_file.getbuffer())\\n  save_path = \"/content/drive/MyDrive/SAMSLR/input-video/\"+vid_file.name\\n  st.write(save_path)\\n  compressed_path = \"/content/drive/MyDrive/SAMSLR/input-video/result_compressed.mp4\"\\n  os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\\n  video_file = open(\\'/content/drive/MyDrive/SAMSLR/input-video/result_compressed.mp4\\', \\'rb\\')\\n  video_bytes = video_file.read()\\n  st.video(video_bytes)\\n  os.system(\"rm /content/drive/MyDrive/SAMSLR/input-video/result_compre...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-98>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/SAMSLR/app.py'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run drive/MyDrive/SAMSLR/app.py & npx localtunnel --port=8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgzXZ1x9XHyS",
        "outputId": "07ad933f-4e42-4818-d805-1cc344a15524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "\n",
            "Error: Invalid value: File does not exist: drive/MyDrive/SAMSLR/app.py\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 5.808s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUiHBYkEXeWE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}